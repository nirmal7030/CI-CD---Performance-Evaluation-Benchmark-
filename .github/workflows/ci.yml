name: CI and Deploy

on:
  push:
    branches: [ "main" ]
  pull_request:

jobs:
  test:
    runs-on: ubuntu-latest
    outputs:
      build_duration: ${{ steps.build_step.outputs.build_duration }}
      test_duration:  ${{ steps.test_step.outputs.test_duration }}
    steps:
      - uses: actions/checkout@v4

      # ---- measure build install time ----
      - name: Setup Python
        id: setup_py
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies (timed)
        id: build_step
        run: |
          set -e
          START=$(date +%s)
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          END=$(date +%s)
          echo "build_duration=$((END-START))" >> "$GITHUB_OUTPUT"

      # ---- measure test time ----
      - name: Run tests (timed)
        id: test_step
        run: |
          set -e
          START=$(date +%s)
          pytest -q
          END=$(date +%s)
          echo "test_duration=$((END-START))" >> "$GITHUB_OUTPUT"

  deploy:
    if: github.ref == 'refs/heads/main'
    needs: test
    runs-on: ubuntu-latest
    steps:
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id:     ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region:            ${{ secrets.AWS_REGION }}

      # ---- measure deploy time (SSM build+run) ----
      - name: Redeploy container on EC2 via SSM (timed)
        id: deploy_step
        continue-on-error: true   # don't fail whole job if SSM waiter reports "Failed"
        env:
          EC2_INSTANCE_ID: ${{ secrets.EC2_INSTANCE_ID }}
          SECRET_KEY:      ${{ secrets.SECRET_KEY }}
          BENCH_API_KEY:   ${{ secrets.BENCH_API_KEY }}
        run: |
          set -e

          echo "Redeploying on EC2 instance: $EC2_INSTANCE_ID"

          # Build SSM command JSON on the runner (ENV will expand here)
          cat > ssm-commands.json <<EOF
          {
            "commands": [
              "set -e",
              "cd /opt/cicd-benchmark || exit 1",
              "git pull --rebase || true",
              "/usr/bin/docker build -t cicd-benchmark:prod .",
              "/usr/bin/docker rm -f cicdbench || true",
              "/usr/bin/docker run -d --name cicdbench -p 80:8000 \
                -e DEBUG=0 \
                -e SECRET_KEY=$SECRET_KEY \
                -e ALLOWED_HOSTS=* \
                -e BENCH_API_KEY=$BENCH_API_KEY \
                cicd-benchmark:prod",
              "/usr/bin/docker exec cicdbench python manage.py migrate --noinput"
            ]
          }
          EOF

          START=$(date +%s)

          CMD_ID=$(aws ssm send-command \
            --instance-ids "$EC2_INSTANCE_ID" \
            --document-name "AWS-RunShellScript" \
            --comment "Redeploy cicd-benchmark" \
            --parameters file://ssm-commands.json \
            --query "Command.CommandId" --output text)

          echo "SSM command id: $CMD_ID"

          # This may occasionally report Failed even if app ends up fine.
          # Because we set continue-on-error: true, the workflow won't stop.
          aws ssm wait command-executed \
            --command-id "$CMD_ID" \
            --instance-id "$EC2_INSTANCE_ID" || echo "SSM waiter reported failure; continuing anyway."

          END=$(date +%s)
          echo "deploy_duration=$((END-START))" >> "$GITHUB_OUTPUT"

      # ---- POST NOVEL METRICS (LCE, PRT, SMO, DEPT, CLBC) TO DJANGO ----
      - name: Post novel metrics to app
        env:
          # IMPORTANT:
          # Set APP_BASE_URL secret to your EC2 public DNS, e.g.
          #   ec2-44-210-105-106.compute-1.amazonaws.com
          # or:
          #   http://ec2-44-210-105-106.compute-1.amazonaws.com
          APP_BASE_URL:  ${{ secrets.APP_BASE_URL }}
          BENCH_API_KEY: ${{ secrets.BENCH_API_KEY }}
          BUILD_DUR:     ${{ needs.test.outputs.build_duration }}
          TEST_DUR:      ${{ needs.test.outputs.test_duration }}
          DEPLOY_DUR:    ${{ steps.deploy_step.outputs.deploy_duration }}
        run: |
          set -e

          # --- Sanitise APP_BASE_URL so curl always gets a valid URL ---
          RAW_URL="$APP_BASE_URL"

          # Strip quotes and whitespace that might have been typed into the secret
          BASE_URL="$(echo "$RAW_URL" | tr -d '\"'\''[:space:]')"

          if [ -z "$BASE_URL" ]; then
            echo "ERROR: APP_BASE_URL secret is empty after sanitising."
            exit 1
          fi

          # If it doesn't start with http:// or https://, assume http://
          case "$BASE_URL" in
            http://*|https://*) ;;
            *) BASE_URL="http://$BASE_URL" ;;
          esac

          echo "Using BASE_URL=$BASE_URL (GitHub will mask the host in logs)"

          # Ensure numeric defaults
          BUILD_DUR=${BUILD_DUR:-0}
          TEST_DUR=${TEST_DUR:-0}
          DEPLOY_DUR=${DEPLOY_DUR:-0}

          echo "BUILD_DUR=$BUILD_DUR"
          echo "TEST_DUR=$TEST_DUR"
          echo "DEPLOY_DUR=$DEPLOY_DUR"

          # ----- Simple approximations for your novel metrics -----
          # LCE (Layer Cache Efficiency): high if build is fast
          LCE=$(( 100 - BUILD_DUR / 2 ))
          if [ "$LCE" -lt 0 ]; then LCE=0; fi
          if [ "$LCE" -gt 100 ]; then LCE=100; fi

          # PRT (Pipeline Recovery Time): use deploy duration for now
          PRT=$DEPLOY_DUR

          # SMO (Secrets Management Overhead): constant placeholder in seconds
          SMO=1

          # DEPT (Dynamic Env Provisioning Time): use deploy duration
          DEPT=$DEPLOY_DUR

          # CLBC (Cross-Layer Build Consistency): 100 if pipeline succeeded
          CLBC=100

          # Build JSON payload for /api/metrics/ingest
          cat > payload.json <<EOF
          {
            "source": "github",
            "workflow": "${{ github.workflow }}",
            "run_id": "${{ github.run_id }}",
            "run_attempt": "${{ github.run_attempt }}",
            "branch": "${{ github.ref_name }}",
            "commit_sha": "${{ github.sha }}",

            "lce":  $LCE,
            "prt":  $PRT,
            "smo":  $SMO,
            "dept": $DEPT,
            "clbc": $CLBC,

            "notes": "auto-ingest of novel metrics from CI"
          }
          EOF

          echo "Payload to send:"
          cat payload.json

          curl -sS -X POST "$BASE_URL/api/metrics/ingest" \
            -H "Content-Type: application/json" \
            -H "X-Bench-Key: $BENCH_API_KEY" \
            --data @payload.json
