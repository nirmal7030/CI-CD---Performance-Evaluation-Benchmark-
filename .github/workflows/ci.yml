name: CI and Deploy

on:
  push:
    branches: [ "main" ]
  pull_request:

jobs:
  test:
    runs-on: ubuntu-latest
    outputs:
      build_duration: ${{ steps.build_step.outputs.build_duration }}
      test_duration:  ${{ steps.test_step.outputs.test_duration }}
    steps:
      - uses: actions/checkout@v4

      # ---- measure build install time ----
      - name: Setup Python
        id: setup_py
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies (timed)
        id: build_step
        run: |
          START=$(date +%s)
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          END=$(date +%s)
          echo "build_duration=$((END-START))" >> $GITHUB_OUTPUT

      # ---- measure test time ----
      - name: Run tests (timed)
        id: test_step
        run: |
          START=$(date +%s)
          pytest -q
          END=$(date +%s)
          echo "test_duration=$((END-START))" >> $GITHUB_OUTPUT

  deploy:
    if: github.ref == 'refs/heads/main'
    needs: test
    runs-on: ubuntu-latest
    steps:
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id:     ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region:            ${{ secrets.AWS_REGION }}

      # ---- measure deploy time (SSM build+run) ----
      - name: Redeploy container on EC2 via SSM (timed)
        id: deploy_step
        env:
          EC2_INSTANCE_ID: ${{ secrets.EC2_INSTANCE_ID }}
          SECRET_KEY:      ${{ secrets.SECRET_KEY }}
          BENCH_API_KEY:   ${{ secrets.BENCH_API_KEY }}
        run: |
          set -e

          # Build SSM command JSON (on the runner)
          cat > ssm-commands.json <<'JSON'
          {
            "commands": [
              "set -e",
              "cd /opt/cicd-benchmark || exit 1",
              "git pull --rebase || true",
              "/usr/bin/docker build -t cicd-benchmark:prod .",
              "/usr/bin/docker rm -f cicdbench || true",
              "/usr/bin/docker run -d --name cicdbench -p 80:8000 \
                -e DEBUG=0 \
                -e SECRET_KEY=$SECRET_KEY \
                -e ALLOWED_HOSTS=* \
                -e BENCH_API_KEY=$BENCH_API_KEY \
                cicd-benchmark:prod"
            ]
          }
          JSON

          START=$(date +%s)
          aws ssm send-command \
            --instance-ids "$EC2_INSTANCE_ID" \
            --document-name "AWS-RunShellScript" \
            --comment "Redeploy cicd-benchmark" \
            --parameters file://ssm-commands.json \
            --query "Command.CommandId" --output text > cmdid.txt

          CMD_ID=$(cat cmdid.txt)
          aws ssm wait command-executed \
            --command-id "$CMD_ID" \
            --instance-id "$EC2_INSTANCE_ID"

          END=$(date +%s)
          echo "deploy_duration=$((END-START))" >> $GITHUB_OUTPUT

      # ---- POST NOVEL METRICS (LCE, PRT, SMO, DEPT, CLBC) TO DJANGO ----
      - name: Post novel metrics to app
        env:
          APP_BASE_URL:  ${{ secrets.APP_BASE_URL }}   # e.g. http://ec2-xx-xx-xx-xx.compute-1.amazonaws.com
          BENCH_API_KEY: ${{ secrets.BENCH_API_KEY }}
          BUILD_DUR:     ${{ needs.test.outputs.build_duration }}
          TEST_DUR:      ${{ needs.test.outputs.test_duration }}
          DEPLOY_DUR:    ${{ steps.deploy_step.outputs.deploy_duration }}
        run: |
          set -e

          # Make sure we have numeric values
          BUILD_DUR=${BUILD_DUR:-0}
          TEST_DUR=${TEST_DUR:-0}
          DEPLOY_DUR=${DEPLOY_DUR:-0}

          # Example simple mapping from timings to novel metrics:
          # These are placeholders you can refine based on your thesis formulas.
          # LCE  â†’ higher if build is fast (just a rough heuristic)
          LCE=$(python - <<PY
bd = float("${BUILD_DUR}")
val = 100.0 - min(40.0, bd * 0.5)
print(round(max(0.0, min(100.0, val)), 2))
PY
)

          # PRT (pipeline recovery time) ~ use deploy duration for now
          PRT=${DEPLOY_DUR}

          # SMO (secrets overhead) ~ constant placeholder (seconds)
          SMO=1.0

          # DEPT (dynamic env provisioning) ~ use a part of deploy duration
          DEPT=${DEPLOY_DUR}

          # CLBC (cross-layer consistency) ~ 100 if pipeline succeeded
          CLBC=100.0

          # Build JSON payload for /api/metrics/ingest
          cat > payload.json <<JSON
          {
            "source": "github",
            "workflow": "${{ github.workflow }}",
            "run_id": "${{ github.run_id }}",
            "run_attempt": "${{ github.run_attempt }}",
            "branch": "${{ github.ref_name }}",
            "commit_sha": "${{ github.sha }}",

            "lce":  $LCE,
            "prt":  $PRT,
            "smo":  $SMO,
            "dept": $DEPT,
            "clbc": $CLBC,

            "notes": "auto-ingest of novel metrics from CI"
          }
JSON

          echo "Payload to send:"
          cat payload.json

          curl -sS -X POST "$APP_BASE_URL/api/metrics/ingest" \
            -H "Content-Type: application/json" \
            -H "X-Bench-Key: $BENCH_API_KEY" \
            --data @payload.json
